import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd  # ë°ì´í„° ì²˜ë¦¬ìš© pandas ì„í¬íŠ¸
import folium  # ì§€ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ folium ì„í¬íŠ¸
from streamlit.components.v1 import html  # Streamlitì—ì„œ HTML ì‚½ì…ì„ ìœ„í•´ import
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode  # AgGridë¥¼ í†µí•œ í…Œì´ë¸” ë Œë”ë§
from langchain_community.vectorstores import FAISS  # ë²¡í„° DBë¡œ FAISS ì‚¬ìš©
from langchain.chains import RetrievalQA  # ì§ˆì˜ì‘ë‹µ ì²´ì¸
from langchain.prompts import PromptTemplate  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
from langchain.schema.messages import BaseMessage, HumanMessage, AIMessage  # LangChain ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ
from langchain.chat_models.base import BaseChatModel  # ì‚¬ìš©ì ì •ì˜ LLM ì¸í„°í˜ì´ìŠ¤ ìƒì†
from langchain.embeddings import HuggingFaceEmbeddings  # ì„ë² ë”© ëª¨ë¸
from langchain.schema import ChatResult  # ì±„íŒ… ê²°ê³¼ íƒ€ì…
from groq import Groq  # Groq API í´ë¼ì´ì–¸íŠ¸

# GroqLlamaChat: BaseChatModelì„ ìƒì†í•˜ì—¬ Groq API í˜¸ì¶œ êµ¬í˜„
class GroqLlamaChat(BaseChatModel):
    groq_api_key: str  # Groq API í‚¤
    model: str = "meta-llama/llama-4-scout-17b-16e-instruct"  # ì‚¬ìš©í•  LLM ëª¨ë¸
    _client: Groq = None  # Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë³€ìˆ˜

    def __init__(self, **data):
        super().__init__(**data)
        self._client = Groq(api_key=self.groq_api_key)

    def _call(self, messages, **kwargs):
        formatted = []
        for m in messages:
            if isinstance(m, HumanMessage):
                formatted.append({"role": "user", "content": m.content})
            elif isinstance(m, AIMessage):
                formatted.append({"role": "assistant", "content": m.content})
        response = self._client.chat.completions.create(
            model=self.model,
            messages=formatted,
        )
        return response.choices[0].message.content

    def _generate(self, messages: list[BaseMessage], stop=None, **kwargs) -> ChatResult:
        content = self._call(messages, **kwargs)
        return ChatResult(generations=[{"text": content, "message": AIMessage(content=content)}])

    @property
    def _llm_type(self):
        return "groq-llama-4"

    @property
    def _identifying_params(self):
        return {"model": self.model}

# ì‹œí¬ë¦¿ì—ì„œ API í‚¤ ë¡œë”© í•¨ìˆ˜
def load_api_key():
    return st.secrets["general"]["API_KEY"]

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë”© í•¨ìˆ˜
def load_template():
    with open("template.txt", "r", encoding="utf-8") as f:
        return f.read()

# QA ì²´ì¸ ë° ìë£Œ ë¡œë”© (ìºì‹œ)
@st.cache_resource
def init_qa_chain():
    api_key = load_api_key()
    template = load_template()
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")
    vectorstore = FAISS.load_local("busan_db", embedding_model, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    llm = GroqLlamaChat(groq_api_key=api_key)
    prompt = PromptTemplate.from_template(template)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True,
    )
    company_df = pd.read_excel("map_busan.xlsx")
    with open("map_company.html", "r", encoding="utf-8") as f:
        map_html = f.read()
    return qa_chain, company_df, map_html

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¶€ì‚° ê¸°ì—… RAG", layout="wide")
st.markdown("""
<style>
#MainMenu, footer, header {visibility: hidden;}
.block-container {padding-top:0 !important;}
header[data-testid=\"stHeader\"] {display:none;}
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ë©”ë‰´
menu = st.sidebar.radio("í˜ì´ì§€ ì„ íƒ", ["ğŸ“Š ë¶€ì‚° ê¸°ì—… RAG ì‹œìŠ¤í…œ", "ğŸ’¬ Groq Chatbot"], key="menu_select")
job_rag = menu == "ğŸ“Š ë¶€ì‚° ê¸°ì—… RAG ì‹œìŠ¤í…œ"
chatbot = menu == "ğŸ’¬ Groq Chatbot"

# JOB BUSAN íƒ­
if job_rag:
    st.title("ğŸš¢ ë¶€ì‚° ì·¨ì—… ìƒë‹´ ì±—ë´‡(JOB BUSAN)")
    if "qa_chain" not in st.session_state:
        st.session_state.qa_chain, st.session_state.company_df, st.session_state.map_html = init_qa_chain()
    if "main_query" not in st.session_state:
        st.session_state.main_query = ""

    query = st.text_input("ğŸ¯ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", value=st.session_state.main_query, key="query_input")
    if st.button("ğŸ’¬ ì§ˆë¬¸ ì‹¤í–‰"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            result = st.session_state.qa_chain.invoke(query)
            st.session_state.gpt_result = result["result"]
            st.session_state.source_documents = result["source_documents"]
            st.session_state.main_query = ""
        st.rerun()
    else:
        st.session_state.main_query = query

    tabs = st.tabs(["âœ… ë‹µë³€","ğŸ“š ì°¸ê³  ë¬¸ì„œ","ğŸŒ ìœ„ì¹˜","ğŸ” ê²€ìƒ‰"])
    with tabs[0]: st.write(st.session_state.get("gpt_result","GPT ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."))
    with tabs[1]:
        for i, d in enumerate(st.session_state.get("source_documents",[])):
            with st.expander(f"ë¬¸ì„œ {i+1}"): st.write(d.page_content)
    with tabs[2]:
        docs = st.session_state.get("source_documents",[])
        names = [d.metadata.get("company") for d in docs if "company" in d.metadata]
        df = st.session_state.company_df[st.session_state.company_df['íšŒì‚¬ëª…'].isin(names)]
        if not df.empty:
            m=folium.Map(location=[df['ìœ„ë„'].mean(),df['ê²½ë„'].mean()],zoom_start=12)
            for _,r in df.iterrows(): folium.CircleMarker(location=[r['ìœ„ë„'],r['ê²½ë„']],radius=5, color='blue',fill=True).add_to(m)
            html(m._repr_html_(),height=600)
        else: st.info("ìœ„ì¹˜ ì •ë³´ ì—†ìŒ")
    with tabs[3]:
        kw=st.text_input("ğŸ” íšŒì‚¬ëª… ê²€ìƒ‰",key="search_input")
        df = st.session_state.company_df[df['íšŒì‚¬ëª…'].str.contains(kw,case=False,na=False)] if kw else st.session_state.company_df
        st.write(df)
        if kw: _=html(st.session_state.map_html,height=480)

# Groq Chatbot íƒ­
if chatbot:
    # ì§ˆë¬¸ ì‹¤í–‰ í™•ì¸
    if not st.session_state.get("source_documents"):
        st.info("ë¨¼ì € JOB BUSAN íƒ­ì—ì„œ 'ì§ˆë¬¸ ì‹¤í–‰'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì°¸ê³  ë¬¸ì„œ í•™ìŠµ
        if not st.session_state.get("system_prompt"):  
            preload = "\n---\n".join([d.page_content for d in st.session_state.source_documents[:3]])
            st.session_state.groq_history = [{"role":"system","content":f"ì°¸ê³  ë¬¸ì„œ ë‚´ìš©:\n{preload}"}]
            st.session_state.system_prompt = True
        # ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ë° íˆìŠ¤í† ë¦¬
        if "groq_chat" not in st.session_state:
            st.session_state.groq_chat = GroqLlamaChat(groq_api_key=load_api_key())
        if "groq_history" not in st.session_state:
            st.session_state.groq_history += [{"role":"assistant","content":"ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
                # UI ë° ëŒ€í™”
        st.markdown("### ğŸ’¬ Groq Chatbot")
        # ëŒ€í™” ë‚´ì—­ í‘œì‹œ
        for msg in st.session_state.groq_history:
            if msg['role'] == 'user':
                cols = st.columns([3,1])
                with cols[1]:
                    st.write(msg['content'])
            elif msg['role'] == 'assistant':
                cols = st.columns([1,3])
                with cols[0]:
                    st.write(msg['content'])
        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="groq_input")
        if user_input:
            st.session_state.groq_history.append({"role":"user","content":user_input})
            history = []
            for m in st.session_state.groq_history:
                if m['role'] == 'user':
                    history.append(HumanMessage(content=m['content']))
                elif m['role'] == 'assistant' or m['role'] == 'system':
                    history.append(AIMessage(content=m['content']))
            ans = st.session_state.groq_chat._call(history)
            st.session_state.groq_history.append({"role":"assistant","content":ans})
            st.rerun()
