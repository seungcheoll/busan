import streamlit as st
import pandas as pd
import folium
from streamlit.components.v1 import html
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema.messages import BaseMessage, HumanMessage, AIMessage
from langchain.chat_models.base import BaseChatModel
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.schema import ChatResult
from groq import Groq

# âœ… ì»¤ìŠ¤í…€ ChatModel í´ë˜ìŠ¤
class GroqLlamaChat(BaseChatModel):
    groq_api_key: str
    model: str = "meta-llama/llama-4-scout-17b-16e-instruct"
    _client: Groq = None

    def __init__(self, **data):
        super().__init__(**data)
        self._client = Groq(api_key=self.groq_api_key)

    def _call(self, messages, **kwargs):
        formatted = []
        for m in messages:
            if isinstance(m, HumanMessage):
                formatted.append({"role": "user", "content": m.content})
            elif isinstance(m, AIMessage):
                formatted.append({"role": "assistant", "content": m.content})
        response = self._client.chat.completions.create(
            model=self.model,
            messages=formatted,
        )
        return response.choices[0].message.content

    def _generate(self, messages: list[BaseMessage], stop=None, **kwargs) -> ChatResult:
        content = self._call(messages, **kwargs)
        return ChatResult(
            generations=[{"text": content, "message": AIMessage(content=content)}]
        )

    @property
    def _llm_type(self):
        return "groq-llama-4"

    @property
    def _identifying_params(self):
        return {"model": self.model}

# âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”© í•¨ìˆ˜
def load_api_key():
    return st.secrets["general"]["API_KEY"]

def load_template():
    with open("template.txt", "r", encoding="utf-8") as file:
        return file.read()

@st.cache_resource
def init_qa_chain():
    api_key = load_api_key()
    template = load_template()

    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")
    vectorstore = FAISS.load_local("busan_db", embedding_model, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    llm = GroqLlamaChat(groq_api_key=api_key)
    prompt = PromptTemplate.from_template(template)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True,
    )

    company_df = pd.read_excel("map_busan.xlsx")
    with open("ì „ì²´ê¸°ì—…_ì§€ë„.html", "r", encoding="utf-8") as f:
        map_html_content = f.read()

    return qa_chain, company_df, map_html_content

# âœ… ì•± ì‹œì‘
st.set_page_config(page_title="ë¶€ì‚° ê¸°ì—… RAG", layout="wide")
st.title("ğŸš¢ ë¶€ì‚° ì·¨ì—… ìƒë‹´ ì±—ë´‡(JOB MAN)")

if "qa_chain" not in st.session_state:
    st.session_state.qa_chain, st.session_state.company_df, st.session_state.map_html = init_qa_chain()

query = st.text_input("ğŸ¯ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ) ì‹ ì… ì‚¬ì›ì´ ì²˜ìŒ ë°›ëŠ” ì—°ë´‰ 3000ë§Œì› ì´ìƒ ë˜ëŠ” ì„ ë°• ì œì¡°ì—… íšŒì‚¬ë¥¼ ì¶”ì²œí•´ì¤˜")

if st.button("ğŸ’¬ ì§ˆë¬¸ ì‹¤í–‰"):
    with st.spinner("ğŸ¤– JOB MANì´ ë¶€ì‚° ê¸°ì—… ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
        result = st.session_state.qa_chain.invoke(query)
        st.session_state.gpt_result = result["result"]
        st.session_state.source_docs = result["source_documents"]

# âœ… íƒ­ êµ¬ì„±
selected_tabs = st.tabs(["âœ… JOB MANì˜ ë‹µë³€", "ğŸ“š ì°¸ê³  ë¬¸ì„œ", "ğŸ—º ê´€ë ¨ ê¸°ì—… ìœ„ì¹˜", "ğŸ“ ë¶€ì‚° ê¸°ì—… ë¶„í¬"])

with selected_tabs[0]:
    st.write(st.session_state.get("gpt_result", "ğŸ”¹ GPT ì‘ë‹µ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."))

with selected_tabs[1]:
    source_docs = st.session_state.get("source_docs", [])
    for i, doc in enumerate(source_docs):
        with st.expander(f"ë¬¸ì„œ {i+1}"):
            st.write(doc.page_content)

with selected_tabs[2]:
    docs = st.session_state.get("source_docs", [])
    company_names = [doc.metadata.get("company") for doc in docs if "company" in doc.metadata]
    matched_df = st.session_state.company_df[st.session_state.company_df['íšŒì‚¬ëª…'].isin(company_names)]

    if not matched_df.empty:
        m = folium.Map(location=[matched_df["ìœ„ë„"].mean(), matched_df["ê²½ë„"].mean()], zoom_start=12, tiles="CartoDB positron")
        for _, row in matched_df.iterrows():
            folium.CircleMarker(
                location=[row["ìœ„ë„"], row["ê²½ë„"]],
                radius=5,
                color="blue",
                fill=True,
                fill_color="blue",
                fill_opacity=0.7,
                popup=row["íšŒì‚¬ëª…"],
                tooltip=row["íšŒì‚¬ëª…"]
            ).add_to(m)
        html(m._repr_html_(), height=500)
    else:
        st.info("í•´ë‹¹ ê¸°ì—… ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

with selected_tabs[3]:
    st.markdown("### ğŸ—º ë¶€ì‚° ê¸°ì—… ë¶„í¬ ë° ê²€ìƒ‰")
    if "search_keyword" not in st.session_state:
        st.session_state.search_keyword = ""

    def reset_search():
        st.session_state.search_keyword = ""
        st.experimental_rerun()

    search_input = st.text_input(
        "ğŸ” íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰ (ì˜ˆ: í˜„ëŒ€, ì‹œìŠ¤í…œ, ì¡°ì„  ë“±)",
        value=st.session_state.search_keyword,
        key="search_input",
        placeholder="ê²€ìƒ‰ì–´ ì…ë ¥ í›„ ì—”í„°"
    )
    st.session_state.search_keyword = search_input

    # í…ìŠ¤íŠ¸ë°•ìŠ¤ ë°”ë¡œ ì•„ë˜ì— ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.search_keyword:
        st.button("ê²€ìƒ‰ ì´ˆê¸°í™”", on_click=reset_search)

    if st.session_state.search_keyword.strip():
        matched_df = st.session_state.company_df[
            st.session_state.company_df["íšŒì‚¬ëª…"].str.contains(st.session_state.search_keyword, case=False, na=False)
        ]
        if matched_df.empty:
            st.warning(f"'{st.session_state.search_keyword}'ë¥¼ í¬í•¨í•˜ëŠ” ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            m = folium.Map(
                location=[matched_df["ìœ„ë„"].mean(), matched_df["ê²½ë„"].mean()],
                zoom_start=12,
                tiles="CartoDB positron"
            )
            for _, row in matched_df.iterrows():
                folium.CircleMarker(
                    location=[row["ìœ„ë„"], row["ê²½ë„"]],
                    radius=5,
                    color="green",
                    fill=True,
                    fill_color="green",
                    fill_opacity=0.7,
                    popup=row["íšŒì‚¬ëª…"],
                    tooltip=row["íšŒì‚¬ëª…"]
                ).add_to(m)
            html(m._repr_html_(), height=600)
            st.caption(f"â€» '{st.session_state.search_keyword}'ë¥¼ í¬í•¨í•œ ê¸°ì—… {len(matched_df)}ê³³ì„ ì§€ë„ì— í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
    else:
        html(st.session_state.map_html, height=600)
        st.caption("â€» ì…ë ¥ ì—†ì´ ì „ì²´ ê¸°ì—… ë¶„í¬ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.")
