# ğŸ“¦ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st                  # ì›¹ ì•± í”„ë ˆì„ì›Œí¬ (ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì•± ë§Œë“¤ ìˆ˜ ìˆìŒ)
import pandas as pd                    # ë°ì´í„° ì²˜ë¦¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì—‘ì…€ì´ë‚˜ í…Œì´ë¸” ë‹¤ë£¨ê¸°)
import folium                          # ì§€ë„ ì‹œê°í™” ë„êµ¬ (ì§€ë„ ìœ„ì— ë§ˆì»¤ í‘œì‹œ ê°€ëŠ¥)
from streamlit.components.v1 import html  # Streamlitì—ì„œ HTML ì½”ë“œ ì‚½ì…í•  ë•Œ ì‚¬ìš©
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode

# LangChain ê´€ë ¨: ì§ˆë¬¸-ë‹µë³€ ì²´ê³„ êµ¬ì¶•ìš©
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema.messages import BaseMessage, HumanMessage, AIMessage
from langchain.chat_models.base import BaseChatModel
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.schema import ChatResult

# Groq API ì—°ë™ìš©
from groq import Groq

# âœ… 1. ì‚¬ìš©ì ì •ì˜ ì±—ë´‡ í´ë˜ìŠ¤ ì •ì˜ (Groq + LLaMA ëª¨ë¸ ì—°ê²°ìš©)
class GroqLlamaChat(BaseChatModel):
    groq_api_key: str
    model: str = "meta-llama/llama-4-scout-17b-16e-instruct"
    _client: Groq = None

    def __init__(self, **data):
        super().__init__(**data)
        self._client = Groq(api_key=self.groq_api_key)

    # ğŸ§  ëŒ€í™” ë©”ì‹œì§€ ì •ë¦¬ í›„ API í˜¸ì¶œ
    def _call(self, messages, **kwargs):
        formatted = []
        for m in messages:
            if isinstance(m, HumanMessage):
                formatted.append({"role": "user", "content": m.content})
            elif isinstance(m, AIMessage):
                formatted.append({"role": "assistant", "content": m.content})
        response = self._client.chat.completions.create(
            model=self.model,
            messages=formatted,
        )
        return response.choices[0].message.content

    # ì‘ë‹µ ìƒì„±
    def _generate(self, messages: list[BaseMessage], stop=None, **kwargs) -> ChatResult:
        content = self._call(messages, **kwargs)
        return ChatResult(
            generations=[{"text": content, "message": AIMessage(content=content)}]
        )

    # ëª¨ë¸ ì •ë³´ ì†ì„± ì •ì˜
    @property
    def _llm_type(self):
        return "groq-llama-4"

    @property
    def _identifying_params(self):
        return {"model": self.model}

# âœ… 2. API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° (Streamlit Secretsì—ì„œ ê°€ì ¸ì˜´)
def load_api_key():
    return st.secrets["general"]["API_KEY"]

# âœ… 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ (ì§ˆë¬¸ì— ì‚¬ìš©í•  í‹€)
def load_template():
    with open("template.txt", "r", encoding="utf-8") as file:
        return file.read()

# âœ… 4. ì²´ì¸ ì´ˆê¸°í™” í•¨ìˆ˜ (ì§ˆë¬¸ ì‘ë‹µ ì²´ê³„ ì¤€ë¹„ + ì§€ë„ ë¡œë”©)
@st.cache_resource
def init_qa_chain():
    api_key = load_api_key()
    template = load_template()

    # ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ (í•œêµ­ì–´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜)
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

    # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
    vectorstore = FAISS.load_local("busan_db", embedding_model, allow_dangerous_deserialization=True)

    # ê²€ìƒ‰ê¸° ì •ì˜ (ìƒìœ„ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    # LLM ì´ˆê¸°í™” (Groq ëª¨ë¸)
    llm = GroqLlamaChat(groq_api_key=api_key)

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = PromptTemplate.from_template(template)

    # QA ì²´ì¸ êµ¬ì„± (ì§ˆë¬¸í•˜ë©´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ì„œ ë‹µë³€ ìƒì„±)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True,
    )

    # ê¸°ì—… ìœ„ì¹˜ ì—‘ì…€ íŒŒì¼ ë¡œë“œ
    company_df = pd.read_excel("map_busan.xlsx")

    # ì „ì²´ ê¸°ì—… ì§€ë„ HTML ë¡œë“œ
    with open("map_company.html", "r", encoding="utf-8") as f:
        map_html_content = f.read()

    return qa_chain, company_df, map_html_content

# âœ… 5. Streamlit ì•± ì´ˆê¸° ì„¤ì •
st.set_page_config(page_title="ë¶€ì‚° ê¸°ì—… RAG", layout="wide")
st.title("ğŸš¢ ë¶€ì‚° ì·¨ì—… ìƒë‹´ ì±—ë´‡(JOB MAN)")

# âœ… 6. ì²´ì¸ ë¡œë”© (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain, st.session_state.company_df, st.session_state.map_html = init_qa_chain()

# ì„¸ì…˜ ìƒíƒœì— query ë³€ìˆ˜ ì´ˆê¸°í™”
if "query" not in st.session_state:
    st.session_state.query = ""

# í…ìŠ¤íŠ¸ ì…ë ¥ê°’ ì €ì¥ìš© ìƒíƒœ
if "main_query" not in st.session_state:
    st.session_state["main_query"] = ""

# ìƒíƒœ ê°’ ê°€ì ¸ì˜¤ê¸°
query = st.session_state["main_query"]

# âœ… 7. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ì°½ í‘œì‹œ
query = st.text_input(
    "ğŸ¯ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
    value=query,
    key="query_input",  # ìœ„ ìƒíƒœì™€ ì—°ê²°ëœ keyëŠ” ì•„ë‹˜
    placeholder="ì˜ˆ: ì—°ë´‰ 3000ë§Œì› ì´ìƒ ì„ ë°• ì œì¡°ì—… ì¶”ì²œ"
)

# âœ… 8. ì§ˆë¬¸ ì‹¤í–‰ ë²„íŠ¼ ëˆ„ë¥´ë©´ ì²˜ë¦¬
if st.button("ğŸ’¬ ì§ˆë¬¸ ì‹¤í–‰"):
    with st.spinner("ğŸ¤– JOB MANì´ ë¶€ì‚° ê¸°ì—… ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
        result = st.session_state.qa_chain.invoke(query)  # ì§ˆë¬¸ ì‹¤í–‰
        st.session_state.gpt_result = result["result"]    # ì‘ë‹µ ì €ì¥
        st.session_state.source_docs = result["source_documents"]  # ë¬¸ì„œ ì €ì¥
        st.session_state["main_query"] = ""  # ì…ë ¥ì°½ ë¹„ìš°ê¸°
        st.rerun()
else:
    st.session_state["main_query"] = query  # ì…ë ¥ ì¤‘ì¼ ë•Œ ì‹¤ì‹œê°„ ì €ì¥

# âœ… 9. ê²°ê³¼ ë³´ì—¬ì¤„ íƒ­ êµ¬ì„±
selected_tabs = st.tabs(["âœ… JOB MANì˜ ë‹µë³€", "ğŸ“š ì°¸ê³  ë¬¸ì„œ", "ğŸŒ ê´€ë ¨ ê¸°ì—… ìœ„ì¹˜", "ğŸ” ë¶€ì‚° ê¸°ì—… ë¶„í¬ ë° ê²€ìƒ‰"])

# GPT ì‘ë‹µ ê²°ê³¼ ì¶œë ¥
with selected_tabs[0]:
    st.write(st.session_state.get("gpt_result", "ğŸ”¹ GPT ì‘ë‹µ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."))

# ì°¸ì¡° ë¬¸ì„œ ë‚´ìš© ì¶œë ¥
with selected_tabs[1]:
    source_docs = st.session_state.get("source_docs", [])
    for i, doc in enumerate(source_docs):
        with st.expander(f"ë¬¸ì„œ {i+1}"):
            st.write(doc.page_content)

# ê´€ë ¨ ê¸°ì—… ìœ„ì¹˜ ì§€ë„ ì¶œë ¥
with selected_tabs[2]:
    docs = st.session_state.get("source_docs", [])
    company_names = [doc.metadata.get("company") for doc in docs if "company" in doc.metadata]
    matched_df = st.session_state.company_df[st.session_state.company_df['íšŒì‚¬ëª…'].isin(company_names)]

    if not matched_df.empty:
        m = folium.Map(location=[matched_df["ìœ„ë„"].mean(), matched_df["ê²½ë„"].mean()], zoom_start=12)
        for _, row in matched_df.iterrows():
            folium.CircleMarker(
                location=[row["ìœ„ë„"], row["ê²½ë„"]],
                radius=5,
                color="blue",
                fill=True,
                fill_color="blue",
                fill_opacity=0.7,
                popup=row["íšŒì‚¬ëª…"],
                tooltip=row["íšŒì‚¬ëª…"]
            ).add_to(m)
        html(m._repr_html_(), height=700)
    else:
        st.info("í•´ë‹¹ ê¸°ì—… ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ê¸°ì—…ëª… ê²€ìƒ‰ ê¸°ë°˜ ì§€ë„ ì‹œê°í™”
with selected_tabs[3]:
    if "search_keyword" not in st.session_state:
        st.session_state.search_keyword = ""
    if "reset_triggered" not in st.session_state:
        st.session_state.reset_triggered = False

    def reset_search():
        st.session_state.search_keyword = ""
        st.session_state["search_input"] = ""
        st.session_state.reset_triggered = True

    search_input = st.text_input(
        label="",
        key="search_input",
        placeholder="ğŸ” íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰ (ì˜ˆ: í˜„ëŒ€, ì‹œìŠ¤í…œ, ì¡°ì„  ë“±)"
    )
    st.session_state.search_keyword = st.session_state.get("search_input", "")

    if st.session_state.search_keyword:
        st.button("ê²€ìƒ‰ ì´ˆê¸°í™”", on_click=reset_search)

    if st.session_state.reset_triggered:
        st.session_state.reset_triggered = False
        st.rerun()

    matched_df = pd.DataFrame()
    if st.session_state.search_keyword.strip():
        matched_df = st.session_state.company_df[
            st.session_state.company_df["íšŒì‚¬ëª…"].str.contains(
                st.session_state.search_keyword,
                case=False,
                na=False
            )
        ]

    col1, col2 = st.columns([2, 1])  # ì§€ë„:í…Œì´ë¸” ë¹„ìœ¨
# ì´ˆê¸°í™”: ì„ íƒí•œ íšŒì‚¬ëª… ìƒíƒœ
if "selected_company_name" not in st.session_state:
    st.session_state.selected_company_name = None

with col1:
    # ğŸ‘‡ ì„ íƒëœ íšŒì‚¬ëª…ìœ¼ë¡œ ì§€ë„ì— í‘œì‹œí•  ê¸°ì—…ë§Œ í•„í„°ë§
    selected_name = st.session_state.get("selected_company_name", None)
    filtered_df = matched_df

    if selected_name:
        filtered_df = matched_df[matched_df["íšŒì‚¬ëª…"] == selected_name]

    if not filtered_df.empty:
        m = folium.Map(
            location=[filtered_df["ìœ„ë„"].mean(), filtered_df["ê²½ë„"].mean()],
            zoom_start=12
        )
        for _, row in filtered_df.iterrows():
            folium.CircleMarker(
                location=[row["ìœ„ë„"], row["ê²½ë„"]],
                radius=5,
                color="crimson" if selected_name else "green",
                fill=True,
                fill_color="crimson" if selected_name else "green",
                fill_opacity=0.7,
                popup=row["íšŒì‚¬ëª…"],
                tooltip=row["íšŒì‚¬ëª…"]
            ).add_to(m)
        html(m._repr_html_(), height=600)
        st.caption(f"â€» '{st.session_state.search_keyword}'ë¥¼ í¬í•¨í•œ ê¸°ì—… {len(filtered_df)}ê³³ì„ ì§€ë„ì— í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
    elif st.session_state.search_keyword.strip():
        st.warning("ğŸ›‘ í•´ë‹¹ ê¸°ì—…ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        html(st.session_state.map_html, height=600)
        st.caption("â€» ì „ì²´ ê¸°ì—… ë¶„í¬ë¥¼ í‘œì‹œ ì¤‘ì…ë‹ˆë‹¤.")

with col2:
    st.markdown("### ğŸ§¾ ê²€ìƒ‰ ê¸°ì—… ì •ë³´")

    if not matched_df.empty:
        gb = GridOptionsBuilder.from_dataframe(
            matched_df[["íšŒì‚¬ëª…", "ë„ë¡œëª…", "ì—…ì¢…ëª…", "ì „í™”ë²ˆí˜¸"]]
        )
        gb.configure_selection("single", use_checkbox=True)
        grid_options = gb.build()

        grid_response = AgGrid(
            matched_df[["íšŒì‚¬ëª…", "ë„ë¡œëª…", "ì—…ì¢…ëª…", "ì „í™”ë²ˆí˜¸"]],
            gridOptions=grid_options,
            update_mode=GridUpdateMode.SELECTION_CHANGED,
            height=535,
            fit_columns_on_grid_load=True,
            return_mode='AS_INPUT'
        )

        selected_rows = grid_response["selected_rows"]

        if isinstance(selected_rows, list) and len(selected_rows) > 0:
            selected_company = selected_rows[0]
            if isinstance(selected_company, dict):
                selected_company_name = selected_company.get("íšŒì‚¬ëª…")
                if selected_company_name:
                    st.session_state.selected_company_name = selected_company_name
                    st.success(f"âœ… ì„ íƒí•œ ê¸°ì—…: {selected_company_name}")
                else:
                    st.warning(f"âŒ 'íšŒì‚¬ëª…' í‚¤ ì—†ìŒ: {list(selected_company.keys())}")
            else:
                st.error("ì„ íƒëœ í–‰ì´ dictê°€ ì•„ë‹™ë‹ˆë‹¤.")
        else:
            if st.session_state.selected_company_name:
                st.info(f"ğŸ” ìµœê·¼ ì„ íƒ: {st.session_state.selected_company_name}")
            else:
                st.info("ğŸ‘ˆ í…Œì´ë¸”ì—ì„œ ê¸°ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.info("ê¸°ì—…ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")
