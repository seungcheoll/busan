# components/qa_utils.py
import streamlit as st
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from components.llm import GroqLlamaChat

# ğŸ”‘ API Key ë¶ˆëŸ¬ì˜¤ê¸°
def load_api_key():
    return st.secrets["general"]["API_KEY"]

# ğŸ§© ì‚¬ìš©ì ìœ í˜•ë³„ í…œí”Œë¦¿ ë¶ˆëŸ¬ì˜¤ê¸°
def load_all_templates():
    templates = {
        "ëŒ€í•™ìƒ": open("template/template_un.txt", "r", encoding="utf-8").read(),
        "ì²« ì·¨ì—… ì¤€ë¹„": open("template/template_first.txt", "r", encoding="utf-8").read(),
        "ì´ì§ ì¤€ë¹„": open("template/template_move.txt", "r", encoding="utf-8").read(),
    }
    return templates

# ğŸ§  ë²¡í„° DB ë° QA ì²´ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
@st.cache_resource
def init_qa_chain(api_key):
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")
    vectorstore = FAISS.load_local("busan_db", embedding_model, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    llm = GroqLlamaChat(groq_api_key=api_key)
    
    company_df = pd.read_excel("map_busan.xlsx")
    with open("map_company.html", "r", encoding="utf-8") as f:
        map_html_content = f.read()

    return llm, retriever, company_df, map_html_content
